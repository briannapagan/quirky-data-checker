{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmr import CollectionQuery, GranuleQuery, ToolQuery, ServiceQuery, VariableQuery\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provider GES_DISC has 1791 to check\n"
     ]
    }
   ],
   "source": [
    "provider = 'GES_DISC'\n",
    "api = CollectionQuery()\n",
    "collections = api.provider(provider).get_all()\n",
    "\n",
    "print('provider ' + provider + ' has ' + str(np.shape(collections)[0]) + ' to check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sad that because GES DISC didn't leverage opendap flags we have to use this\n",
    "# silly way to identify those collections :( )\n",
    "\n",
    "# should we add filter for just checking level 3/4 products? \n",
    "# for now will summarize by this info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provider GES_DISC has 1305 opendap collections to check\n"
     ]
    }
   ],
   "source": [
    "opendap_base_urls = []\n",
    "short_names = []\n",
    "versions = []\n",
    "processing_levels = []\n",
    "native_ids = []\n",
    "\n",
    "for collection in collections:\n",
    "    for element in collection['links']:\n",
    "        if element['rel'] == 'http://esipfed.org/ns/fedsearch/1.1/service#':\n",
    "            # this should return default url so can be on prem or cloud depending on granule\n",
    "            opendap_base_urls.append(element['href'])\n",
    "            processing_levels.append(collection['processing_level_id'])\n",
    "            versions.append(collection['version_id'])\n",
    "            short_names.append(collection['short_name'])\n",
    "            native_ids.append(collection['id'])\n",
    "            break\n",
    "\n",
    "print('provider ' + provider + ' has ' + str(np.shape(short_names)[0]) + ' opendap collections to check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get granule for each collection, try to open with xarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = GranuleQuery()\n",
    "granule = api.short_name(short_names[0]).version(versions[0]).get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767\n",
      "768\n",
      "769\n"
     ]
    }
   ],
   "source": [
    "message_out = []\n",
    "short_names_out = []\n",
    "versions_out = []\n",
    "opendap_urls_out = []\n",
    "processing_levels_out = []\n",
    "\n",
    "for i in range(0,np.shape(short_names)[0]):\n",
    "    print(i)\n",
    "    granule = api.short_name(short_names[i]).version(versions[i]).get(1) \n",
    "    for element in granule[0]['links']:\n",
    "        if 'title' in element:\n",
    "            if element['title'] == 'The OPENDAP location for the granule. (GET DATA : OPENDAP DATA)':\n",
    "                # this should return default url so can be on prem or cloud depending on granule\n",
    "                opendap_url = (element['href'])\n",
    "                opendap_urls_out.append(opendap_url)\n",
    "                try:\n",
    "                    xr.open_dataset(opendap_url)\n",
    "                    message_out.append('success')\n",
    "                    short_names_out.append(short_names[i])\n",
    "                    versions_out.append(versions[i])\n",
    "                    processing_levels_out.append(processing_levels[i])\n",
    "                except Exception as e:\n",
    "                    message_out.append(e)\n",
    "                    short_names_out.append(short_names[i])\n",
    "                    versions_out.append(versions[i])\n",
    "                    processing_levels_out.append(processing_levels[i])\n",
    "\n",
    "        #else:\n",
    "            #message_out.append('no opendap url found')\n",
    "    df_out = pd.DataFrame({'short_name':short_names_out,'version':versions_out,'processing_level':processing_levels_out,'message':message_out,'opendap_url':opendap_urls_out})\n",
    "    df_out.to_csv('results_' + provider +  '.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
